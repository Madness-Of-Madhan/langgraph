{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "GiJMHW1afMqj"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain langchain-community langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain-ollama"
      ],
      "metadata": {
        "id": "HxX8EfN0fUux"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List,Dict, TypedDict\n",
        "from langgraph.graph import StateGraph,START,END\n",
        "from langchain_ollama.llms import OllamaLLM\n",
        "import os"
      ],
      "metadata": {
        "id": "qH0I2mQofcj3"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    messages: List[Dict[str, str]]\n",
        "##Define State"
      ],
      "metadata": {
        "id": "A25AqiuIgAxA"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#intialize StateGraph\n",
        "graph_builder=StateGraph(State)"
      ],
      "metadata": {
        "id": "mf9OxyQogRaO"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm=OllamaLLM(model=\"llama3.1\")"
      ],
      "metadata": {
        "id": "VSIOjEYDghoA"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1Dwjp6AGsFi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "os.environ[\"OLLAMA_BASE_URL\"] = \"https://your-random-subdomain.ngrok-free.app\"\n"
      ],
      "metadata": {
        "id": "05pPiP34rIRb"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OllamaLLM(model=\"llama3.1\")"
      ],
      "metadata": {
        "id": "jnDoYq-UtM0C"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state: State) -> State:\n",
        "    # Extract latest user message for the model\n",
        "    user_message = state[\"messages\"][-1][\"content\"]\n",
        "\n",
        "    # Get LLM response\n",
        "    response = llm.invoke(user_message)\n",
        "\n",
        "    # Append assistant's reply to messages\n",
        "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    return {\"messages\": state[\"messages\"]}"
      ],
      "metadata": {
        "id": "V_CA3wUSgs_W"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create node and add node\n",
        "graph_builder.add_node(\"chatbot\",chatbot)\n",
        "graph_builder.add_edge(START,\"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\",END)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq38x2dnhLl_",
        "outputId": "6cb06bcf-0bac-491c-ecb3-469fb3626f71"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ea8981a9950>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compile graph\n",
        "graph=graph_builder.compile()"
      ],
      "metadata": {
        "id": "uVnEoDjZh8r2"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input:str):\n",
        "  #intialize the state with the user's input\n",
        "  state={\"messages\":[{\"role\":\"user\",\"content\":user_input}]}\n",
        "  for event in graph.stream(state):\n",
        "    for value in event.values():\n",
        "      print(\"Assistant\",value[\"messages\"][-1][\"content\"])\n"
      ],
      "metadata": {
        "id": "v8VPbq7FicS8"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "  while True:\n",
        "    try:\n",
        "      user_input=input(\"User :\")\n",
        "      if user_input.lower()in[\"quit\",\"exit\",\"q\"]:\n",
        "        print(\"Good Bye\")\n",
        "        break\n",
        "      stream_graph_updates(user_input)\n",
        "    except Exception as e:\n",
        "      print(f\"An error occured:{e}\")\n",
        "      break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljs4FUI3oq_5",
        "outputId": "3444e123-e6ab-407e-fc34-fa32e700e830"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User :hello\n",
            "An error occured:[Errno 111] Connection refused\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "60MWic7NpvxC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "9b5078c1-0d45-4861-a0d2-297f023baf88"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1129505489.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1129505489.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    choco install ngrok\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdb71c02"
      },
      "source": [
        "Here's how you can typically set up a tunnel to connect your local Ollama instance to your Colab notebook:\n",
        "\n",
        "1.  **Install ngrok:** If you don't have ngrok installed, download and install it from the official website: [https://ngrok.com/download](https://ngrok.com/download)\n",
        "2.  **Run Ollama:** Make sure your Ollama server is running on your local machine. By default, it usually runs on `localhost:11434`.\n",
        "3.  **Start an ngrok tunnel:** Open a terminal or command prompt on your local machine and run the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "3e2d219a",
        "outputId": "884136e6-859f-4155-8c5f-f417eab6f653"
      },
      "source": [],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-3477860531.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3477860531.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    \\\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xPyaUNkqrvBq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}